"""
æ•°æ®è·å–æ¨¡å—
ä½¿ç”¨Tushare fund_dailyæ¥å£è·å–ETFå†å²æ•°æ®
"""

import tushare as ts
import pandas as pd
import time
from typing import List, Dict, Optional
import logging

from .config import get_config


logger = logging.getLogger(__name__)


class DataFetcher:
    """æ•°æ®è·å–ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®è·å–å™¨"""
        self.config = get_config()
        self.pro = self._init_tushare()
        self.etf_names_cache = {}  # ETFåç§°ç¼“å­˜
        
    def _init_tushare(self) -> ts.pro_api:
        """åˆå§‹åŒ–Tushare API"""
        try:
            pro = ts.pro_api(self.config.tushare_token)
            # æµ‹è¯•è¿æ¥
            pro.query('trade_cal', start_date='20230101', end_date='20230101')
            logger.info("Tushare APIè¿æ¥æˆåŠŸ")
            return pro
        except Exception as e:
            logger.error(f"âŒ Tushare APIè¿æ¥å¤±è´¥: {e}")
            raise
    
    def validate_etf_codes(self, etf_codes: List[str]) -> List[str]:
        """
        éªŒè¯ETFä»£ç æ ¼å¼
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            
        Returns:
            æœ‰æ•ˆçš„ETFä»£ç åˆ—è¡¨
        """
        valid_codes = []
        for code in etf_codes:
            if self._is_valid_etf_code(code):
                valid_codes.append(code)
            else:
                logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆçš„ETFä»£ç : {code}")
        
        if not valid_codes:
            raise ValueError("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ETFä»£ç ï¼")
        
        return valid_codes
    
    def _is_valid_etf_code(self, code: str) -> bool:
        """æ£€æŸ¥ETFä»£ç æ ¼å¼æ˜¯å¦æœ‰æ•ˆ"""
        # åŸºæœ¬æ ¼å¼æ£€æŸ¥ï¼šæ•°å­—.SH æˆ– æ•°å­—.SZ
        if not isinstance(code, str):
            return False
        
        parts = code.split('.')
        if len(parts) != 2:
            return False
        
        if not parts[0].isdigit():
            return False
        
        if parts[1] not in ['SH', 'SZ']:
            return False
        
        return True
    
    def fetch_etf_data(self, etf_codes: Optional[List[str]] = None, 
                      start_date: Optional[str] = None,
                      end_date: Optional[str] = None,
                      fields: Optional[str] = None) -> pd.DataFrame:
        """
        è·å–å¤šåªETFçš„å†å²æ•°æ®
        
        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºé…ç½®ä¸­çš„ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ (YYYYMMDD)
            end_date: ç»“æŸæ—¥æœŸ (YYYYMMDD)
            fields: å­—æ®µåˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„æ•°æ®DataFrame
        """
        # ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼
        etf_codes = etf_codes or self.config.etf_codes
        start_date = start_date or self.config.start_date
        end_date = end_date or self.config.end_date
        fields = fields or self.config.fields
        
        # éªŒè¯ETFä»£ç 
        valid_codes = self.validate_etf_codes(etf_codes)
        
        logger.info(f"ğŸ“Š å¼€å§‹è·å–ETFæ•°æ®: {valid_codes}")
        logger.info(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
        
        data_frames = []
        
        for code in valid_codes:
            try:
                df = self._fetch_single_etf(code, start_date, end_date, fields)
                if df is not None and not df.empty:
                    data_frames.append(df)
                    logger.info(f"âœ… æˆåŠŸè·å– {code} æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
                else:
                    logger.warning(f"âš ï¸ {code} è¿”å›ç©ºæ•°æ®")
                
                # é¿å…APIè°ƒç”¨é¢‘ç‡é™åˆ¶
                time.sleep(0.1)
                
            except Exception as e:
                logger.error(f"âŒ è·å– {code} æ•°æ®å¤±è´¥: {e}")
                continue
        
        if not data_frames:
            raise ValueError("âŒ æ‰€æœ‰ETFæ•°æ®è·å–å¤±è´¥ï¼")
        
        # åˆå¹¶æ•°æ®
        combined_df = self._merge_data(data_frames)
        
        logger.info(f"âœ… æ•°æ®è·å–å®Œæˆï¼Œå…± {len(combined_df)} ä¸ªäº¤æ˜“æ—¥")
        return combined_df
    
    def _fetch_single_etf(self, etf_code: str, start_date: str, 
                         end_date: str, fields: str) -> Optional[pd.DataFrame]:
        """
        è·å–å•åªETFçš„æ•°æ®
        
        Args:
            etf_code: ETFä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            fields: å­—æ®µåˆ—è¡¨
            
        Returns:
            ETFæ•°æ®DataFrame
        """
        try:
            df = self.pro.fund_daily(
                ts_code=etf_code,
                start_date=start_date,
                end_date=end_date,
                fields=fields
            )
            
            if df is None or df.empty:
                return None
            
            # æŒ‰æ—¥æœŸæ’åº
            df = df.sort_values('trade_date')
            
            # é‡å‘½ååˆ—ä»¥é¿å…åˆå¹¶æ—¶å†²çª
            df = df.rename(columns={'close': etf_code})
            
            return df
            
        except Exception as e:
            if "ç§¯åˆ†ä¸è¶³" in str(e):
                raise ValueError(
                    f"âŒ Tushareç§¯åˆ†ä¸è¶³ï¼\n"
                    f"è·å– {etf_code} æ•°æ®éœ€è¦2000+ç§¯åˆ†\n"
                    f"è¯·è®¿é—® https://tushare.pro è´­ä¹°ç§¯åˆ†"
                )
            elif "æ¥å£æƒé™" in str(e):
                raise ValueError(
                    f"âŒ æ¥å£æƒé™ä¸è¶³ï¼\n"
                    f"è¯·æ£€æŸ¥fund_dailyæ¥å£æƒé™æˆ–è”ç³»Tushareå®¢æœ"
                )
            else:
                raise
    
    def _merge_data(self, data_frames: List[pd.DataFrame]) -> pd.DataFrame:
        """
        åˆå¹¶å¤šåªETFæ•°æ®
        
        Args:
            data_frames: ETFæ•°æ®åˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„DataFrame
        """
        if not data_frames:
            raise ValueError("æ²¡æœ‰æ•°æ®å¯åˆå¹¶")
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªDataFrameä½œä¸ºåŸºç¡€
        combined_df = data_frames[0]
        
        # é€ä¸ªåˆå¹¶å…¶ä»–DataFrame
        for df in data_frames[1:]:
            combined_df = pd.merge(
                combined_df, 
                df[['trade_date', df.columns[-1]]],  # åªä¿ç•™æ—¥æœŸå’Œä»·æ ¼åˆ—
                on='trade_date', 
                how='inner'
            )
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        self._validate_merged_data(combined_df)
        
        return combined_df
    
    def _validate_merged_data(self, df: pd.DataFrame) -> None:
        """
        éªŒè¯åˆå¹¶åçš„æ•°æ®
        
        Args:
            df: åˆå¹¶åçš„DataFrame
        """
        if df.empty:
            raise ValueError("åˆå¹¶åçš„æ•°æ®ä¸ºç©º")
        
        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing_count = df.isnull().sum().sum()
        if missing_count > 0:
            logger.warning(f"âš ï¸ æ•°æ®ä¸­å­˜åœ¨ {missing_count} ä¸ªç¼ºå¤±å€¼")
            # å¯ä»¥é€‰æ‹©å¡«å……æˆ–åˆ é™¤ï¼Œè¿™é‡Œé€‰æ‹©åˆ é™¤
            df.dropna(inplace=True)
            logger.info(f"âœ… å·²åˆ é™¤ç¼ºå¤±å€¼ï¼Œå‰©ä½™ {len(df)} æ¡è®°å½•")
        
        # æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
        if len(df) < 100:
            logger.warning("âš ï¸ æ•°æ®é‡è¾ƒå°‘ï¼Œå¯èƒ½å½±å“åˆ†æç»“æœ")
        
        # æ£€æŸ¥æ—¥æœŸè¿ç»­æ€§
        df['trade_date'] = pd.to_datetime(df['trade_date'])
        date_diff = df['trade_date'].diff().dt.days
        if (date_diff > 10).any():
            logger.warning("âš ï¸ æ•°æ®ä¸­å­˜åœ¨è¾ƒå¤§çš„æ—¥æœŸé—´éš”")

    def get_etf_names(self, etf_codes: List[str]) -> Dict[str, str]:
        """
        è·å–ETFä¸­æ–‡åç§°åˆ—è¡¨

        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨

        Returns:
            ETFä»£ç åˆ°ä¸­æ–‡åç§°çš„æ˜ å°„å­—å…¸
        """
        etf_names = {}

        logger.info("ğŸ“‹ è·å–ETFä¸­æ–‡åç§°...")

        for code in etf_codes:
            # æ£€æŸ¥ç¼“å­˜
            if code in self.etf_names_cache:
                etf_names[code] = self.etf_names_cache[code]
                continue

            try:
                # è°ƒç”¨Tushare APIè·å–ETFåŸºæœ¬ä¿¡æ¯
                df = self.pro.fund_basic(ts_code=code)

                if not df.empty and 'name' in df.columns:
                    name = df.iloc[0]['name']
                    etf_names[code] = name
                    self.etf_names_cache[code] = name  # ç¼“å­˜ç»“æœ
                    logger.info(f"âœ… {code}: {name}")
                else:
                    etf_names[code] = f"{code}(æœªçŸ¥åç§°)"
                    logger.warning(f"âš ï¸ æ— æ³•è·å– {code} çš„åç§°ä¿¡æ¯")

                # é¿å…APIè°ƒç”¨é¢‘ç‡é™åˆ¶
                time.sleep(0.1)

            except Exception as e:
                etf_names[code] = f"{code}(è·å–å¤±è´¥)"
                logger.error(f"âŒ è·å– {code} åç§°å¤±è´¥: {e}")

        logger.info(f"âœ… æˆåŠŸè·å– {len([k for k, v in etf_names.items() if not 'å¤±è´¥' in v and not 'æœªçŸ¥' in v])}/{len(etf_codes)} ä¸ªETFåç§°")
        return etf_names

    def get_etf_name(self, etf_code: str) -> str:
        """
        è·å–å•ä¸ªETFçš„ä¸­æ–‡åç§°

        Args:
            etf_code: ETFä»£ç 

        Returns:
            ETFä¸­æ–‡åç§°
        """
        names = self.get_etf_names([etf_code])
        return names.get(etf_code, f"{etf_code}(æœªçŸ¥)")


def get_data_fetcher() -> DataFetcher:
    """è·å–æ•°æ®è·å–å™¨å®ä¾‹"""
    return DataFetcher()