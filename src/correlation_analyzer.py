"""
ç›¸å…³æ€§åˆ†ææ¨¡å—
åˆ†æETFé—´ç›¸å…³æ€§åŠå¯¹æŠ•èµ„ç»„åˆé£é™©çš„å½±å“
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Any, Optional
import logging
import os

# å¯¼å…¥å­—ä½“é…ç½®
from src.font_config import setup_chinese_font

# è®¾ç½®ä¸­æ–‡å­—ä½“
setup_chinese_font()

logger = logging.getLogger(__name__)


class CorrelationAnalyzer:
    """ç›¸å…³æ€§åˆ†æå™¨"""

    def __init__(self, high_correlation_threshold: float = 0.7,
                 moderate_correlation_threshold: float = 0.5):
        """
        åˆå§‹åŒ–ç›¸å…³æ€§åˆ†æå™¨

        Args:
            high_correlation_threshold: é«˜ç›¸å…³æ€§é˜ˆå€¼ï¼Œé»˜è®¤0.7
            moderate_correlation_threshold: ä¸­ç­‰ç›¸å…³æ€§é˜ˆå€¼ï¼Œé»˜è®¤0.5
        """
        self.high_threshold = high_correlation_threshold
        self.moderate_threshold = moderate_correlation_threshold
        self.correlation_matrix = None
        self.high_correlation_pairs = []
        self.moderate_correlation_pairs = []

    def calculate_correlation_matrix(self, returns: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—ETFé—´ç›¸å…³æ€§çŸ©é˜µ

        Args:
            returns: å„ETFæ—¥æ”¶ç›Šç‡DataFrame

        Returns:
            ç›¸å…³æ€§çŸ©é˜µDataFrame
        """
        logger.info("ğŸ”— è®¡ç®—ETFé—´ç›¸å…³æ€§çŸ©é˜µ...")

        try:
            # è®¡ç®—Pearsonç›¸å…³ç³»æ•°
            self.correlation_matrix = returns.corr(method='pearson')

            logger.info("âœ… ç›¸å…³æ€§çŸ©é˜µè®¡ç®—å®Œæˆ")
            return self.correlation_matrix

        except Exception as e:
            logger.error(f"âŒ ç›¸å…³æ€§çŸ©é˜µè®¡ç®—å¤±è´¥: {e}")
            raise

    def identify_correlation_risks(self) -> Dict[str, Any]:
        """
        è¯†åˆ«ç›¸å…³æ€§é£é™©

        Returns:
            ç›¸å…³æ€§é£é™©åˆ†æç»“æœ
        """
        if self.correlation_matrix is None:
            raise ValueError("è¯·å…ˆè®¡ç®—ç›¸å…³æ€§çŸ©é˜µ")

        logger.info("âš ï¸ è¯†åˆ«ç›¸å…³æ€§é£é™©...")

        risk_analysis = {
            'high_correlation_pairs': [],
            'moderate_correlation_pairs': [],
            'average_correlation': 0,
            'max_correlation': 0,
            'correlation_distribution': {},
            'risk_assessment': {},
            'diversification_score': 0
        }

        try:
            # è¯†åˆ«é«˜ç›¸å…³æ€§å’Œä¸­ç­‰ç›¸å…³æ€§ETFå¯¹
            for i in range(len(self.correlation_matrix.columns)):
                for j in range(i + 1, len(self.correlation_matrix.columns)):
                    etf1 = self.correlation_matrix.columns[i]
                    etf2 = self.correlation_matrix.columns[j]
                    correlation = self.correlation_matrix.iloc[i, j]

                    if abs(correlation) >= self.high_threshold:
                        risk_analysis['high_correlation_pairs'].append({
                            'etf1': etf1,
                            'etf2': etf2,
                            'correlation': correlation,
                            'risk_level': 'é«˜é£é™©'
                        })
                    elif abs(correlation) >= self.moderate_threshold:
                        risk_analysis['moderate_correlation_pairs'].append({
                            'etf1': etf1,
                            'etf2': etf2,
                            'correlation': correlation,
                            'risk_level': 'ä¸­ç­‰é£é™©'
                        })

            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
            upper_triangle = self.correlation_matrix.where(
                np.triu(np.ones(self.correlation_matrix.shape), k=1).astype(bool)
            ).stack()

            risk_analysis['average_correlation'] = upper_triangle.mean()
            risk_analysis['max_correlation'] = upper_triangle.abs().max()

            # ç›¸å…³æ€§åˆ†å¸ƒç»Ÿè®¡
            risk_analysis['correlation_distribution'] = {
                'high_correlation_count': len([x for x in upper_triangle if abs(x) >= self.high_threshold]),
                'moderate_correlation_count': len([x for x in upper_triangle if self.moderate_threshold <= abs(x) < self.high_threshold]),
                'low_correlation_count': len([x for x in upper_triangle if abs(x) < self.moderate_threshold]),
                'total_pairs': len(upper_triangle)
            }

            # é£é™©è¯„ä¼°
            risk_analysis['risk_assessment'] = self._assess_correlation_risk(risk_analysis)

            # åˆ†æ•£åŒ–è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
            risk_analysis['diversification_score'] = self._calculate_diversification_score(upper_triangle)

            logger.info("âœ… ç›¸å…³æ€§é£é™©è¯†åˆ«å®Œæˆ")
            return risk_analysis

        except Exception as e:
            logger.error(f"âŒ ç›¸å…³æ€§é£é™©è¯†åˆ«å¤±è´¥: {e}")
            raise

    def _assess_correlation_risk(self, risk_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¯„ä¼°ç›¸å…³æ€§é£é™©ç­‰çº§

        Args:
            risk_analysis: é£é™©åˆ†ææ•°æ®

        Returns:
            é£é™©è¯„ä¼°ç»“æœ
        """
        high_count = len(risk_analysis['high_correlation_pairs'])
        moderate_count = len(risk_analysis['moderate_correlation_pairs'])
        avg_corr = risk_analysis['average_correlation']

        if high_count >= 3 or avg_corr >= 0.6:
            risk_level = "é«˜é£é™©"
            risk_color = "red"
            risk_score = 80 + min(20, high_count * 5)
        elif high_count >= 1 or moderate_count >= 3 or avg_corr >= 0.4:
            risk_level = "ä¸­ç­‰é£é™©"
            risk_color = "orange"
            risk_score = 40 + min(40, high_count * 10 + moderate_count * 5)
        else:
            risk_level = "ä½é£é™©"
            risk_color = "green"
            risk_score = min(40, moderate_count * 8)

        return {
            'risk_level': risk_level,
            'risk_color': risk_color,
            'risk_score': risk_score,
            'description': self._get_risk_description(risk_level, high_count, moderate_count, avg_corr)
        }

    def _get_risk_description(self, risk_level: str, high_count: int,
                            moderate_count: int, avg_corr: float) -> str:
        """è·å–é£é™©æè¿°"""
        if risk_level == "é«˜é£é™©":
            return f"æŠ•èµ„ç»„åˆå­˜åœ¨{high_count}å¯¹é«˜ç›¸å…³æ€§ETFï¼Œå¹³å‡ç›¸å…³æ€§{avg_corr:.2f}ï¼Œåˆ†æ•£åŒ–ç¨‹åº¦ä¸¥é‡ä¸è¶³ï¼Œå»ºè®®é‡æ–°è¯„ä¼°é…ç½®ã€‚"
        elif risk_level == "ä¸­ç­‰é£é™©":
            return f"æŠ•èµ„ç»„åˆå­˜åœ¨{high_count}å¯¹é«˜ç›¸å…³æ€§å’Œ{moderate_count}å¯¹ä¸­ç­‰ç›¸å…³æ€§ETFï¼Œå¹³å‡ç›¸å…³æ€§{avg_corr:.2f}ï¼Œå…·æœ‰ä¸€å®šé›†ä¸­é£é™©ï¼Œå»ºè®®é€‚åº¦åˆ†æ•£ã€‚"
        else:
            return f"æŠ•èµ„ç»„åˆç›¸å…³æ€§è¾ƒä½ï¼Œå¹³å‡ç›¸å…³æ€§{avg_corr:.2f}ï¼Œåˆ†æ•£åŒ–ç¨‹åº¦è‰¯å¥½ã€‚"

    def _calculate_diversification_score(self, correlations: pd.Series) -> float:
        """
        è®¡ç®—åˆ†æ•£åŒ–è¯„åˆ†

        Args:
            correlations: ç›¸å…³æ€§ç³»æ•°Series

        Returns:
            åˆ†æ•£åŒ–è¯„åˆ†ï¼ˆ0-100ï¼‰
        """
        # åˆ†æ•£åŒ–è¯„åˆ† = 100 * (1 - å¹³å‡ç»å¯¹ç›¸å…³æ€§)
        avg_abs_corr = correlations.abs().mean()
        score = 100 * (1 - avg_abs_corr)
        return max(0, min(100, score))

    def generate_correlation_heatmap(self, save_path: str = None,
                                   output_dir: str = "outputs") -> str:
        """
        ç”Ÿæˆç›¸å…³æ€§çƒ­åŠ›å›¾

        Args:
            save_path: ä¿å­˜æ–‡ä»¶å
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if self.correlation_matrix is None:
            raise ValueError("è¯·å…ˆè®¡ç®—ç›¸å…³æ€§çŸ©é˜µ")

        logger.info("ğŸ”¥ ç”Ÿæˆç›¸å…³æ€§çƒ­åŠ›å›¾...")

        try:
            # å¼ºåˆ¶è®¾ç½®ä¸­æ–‡å­—ä½“
            from matplotlib.font_manager import FontProperties
            chinese_font = FontProperties(family='AR PL UMing CN')

            plt.figure(figsize=(12, 10))

            # åˆ›å»ºçƒ­åŠ›å›¾
            mask = np.triu(np.ones_like(self.correlation_matrix, dtype=bool))

            # ä½¿ç”¨è‡ªå®šä¹‰é¢œè‰²æ˜ å°„
            cmap = sns.diverging_palette(240, 10, as_cmap=True)

            sns.heatmap(
                self.correlation_matrix,
                mask=mask,
                annot=True,
                cmap=cmap,
                center=0,
                square=True,
                linewidths=0.5,
                cbar_kws={"shrink": 0.8},
                fmt='.3f',
                annot_kws={'size': 10}
            )

            plt.title('ETFç›¸å…³æ€§çŸ©é˜µçƒ­åŠ›å›¾', fontsize=16, fontweight='bold', pad=20, fontproperties=chinese_font)
            plt.xlabel('ETFä»£ç ', fontsize=12, fontproperties=chinese_font)
            plt.ylabel('ETFä»£ç ', fontsize=12, fontproperties=chinese_font)
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)

            # è°ƒæ•´å¸ƒå±€
            plt.tight_layout()

            # ä¿å­˜å›¾è¡¨
            if save_path is None:
                save_path = 'correlation_heatmap.png'

            full_path = os.path.join(output_dir, save_path)
            plt.savefig(full_path, dpi=300, bbox_inches='tight')
            plt.close()

            logger.info(f"âœ… ç›¸å…³æ€§çƒ­åŠ›å›¾å·²ä¿å­˜: {full_path}")
            return full_path

        except Exception as e:
            logger.error(f"âŒ ç›¸å…³æ€§çƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥: {e}")
            raise

    def generate_correlation_report(self, returns: pd.DataFrame,
                                  optimal_weights: np.ndarray,
                                  etf_codes: List[str]) -> Dict[str, Any]:
        """
        ç”Ÿæˆå®Œæ•´çš„ç›¸å…³æ€§åˆ†ææŠ¥å‘Š

        Args:
            returns: å„ETFæ—¥æ”¶ç›Šç‡DataFrame
            optimal_weights: æœ€ä¼˜æƒé‡å‘é‡
            etf_codes: ETFä»£ç åˆ—è¡¨

        Returns:
            ç›¸å…³æ€§åˆ†ææŠ¥å‘Š
        """
        logger.info("ğŸ“Š ç”Ÿæˆç›¸å…³æ€§åˆ†ææŠ¥å‘Š...")

        try:
            # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
            self.calculate_correlation_matrix(returns)

            # è¯†åˆ«ç›¸å…³æ€§é£é™©
            risk_analysis = self.identify_correlation_risks()

            # åˆ†ææƒé‡ä¸ç›¸å…³æ€§çš„å…³ç³»
            weight_correlation_analysis = self._analyze_weights_with_correlation(
                optimal_weights, etf_codes
            )

            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            optimization_suggestions = self._generate_optimization_suggestions(
                risk_analysis, weight_correlation_analysis
            )

            # ç”Ÿæˆçƒ­åŠ›å›¾
            heatmap_path = self.generate_correlation_heatmap()

            report = {
                'correlation_matrix': self.correlation_matrix.to_dict(),
                'risk_analysis': risk_analysis,
                'weight_correlation_analysis': weight_correlation_analysis,
                'optimization_suggestions': optimization_suggestions,
                'heatmap_path': heatmap_path,
                'analysis_summary': self._generate_analysis_summary(risk_analysis)
            }

            logger.info("âœ… ç›¸å…³æ€§åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return report

        except Exception as e:
            logger.error(f"âŒ ç›¸å…³æ€§åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            raise

    def _analyze_weights_with_correlation(self, optimal_weights: np.ndarray,
                                        etf_codes: List[str]) -> Dict[str, Any]:
        """
        åˆ†ææƒé‡é…ç½®ä¸ç›¸å…³æ€§çš„å…³ç³»

        Args:
            optimal_weights: æœ€ä¼˜æƒé‡å‘é‡
            etf_codes: ETFä»£ç åˆ—è¡¨

        Returns:
            æƒé‡ç›¸å…³æ€§åˆ†æç»“æœ
        """
        weight_dict = dict(zip(etf_codes, optimal_weights))

        # æ‰¾å‡ºæƒé‡æœ€å¤§çš„ETF
        top_weighted_etfs = sorted(
            [(etf, weight) for etf, weight in weight_dict.items() if weight > 0.01],
            key=lambda x: x[1], reverse=True
        )[:5]

        # åˆ†ææƒé‡æœ€å¤§ETFä¸å…¶ä»–é«˜ç›¸å…³æ€§ETFçš„ç»„åˆ
        high_weight_high_correlation = []
        for etf, weight in top_weighted_etfs:
            if etf in self.correlation_matrix.columns:
                # æ‰¾å‡ºä¸è¯¥ETFé«˜ç›¸å…³çš„å…¶ä»–ETF
                correlated_etfs = []
                for other_etf in self.correlation_matrix.columns:
                    if other_etf != etf:
                        correlation = self.correlation_matrix.loc[etf, other_etf]
                        if abs(correlation) >= self.moderate_threshold:
                            other_weight = weight_dict.get(other_etf, 0)
                            if other_weight > 0.01:
                                correlated_etfs.append({
                                    'etf': other_etf,
                                    'correlation': correlation,
                                    'weight': other_weight,
                                    'combined_weight': weight + other_weight
                                })

                if correlated_etfs:
                    high_weight_high_correlation.append({
                        'primary_etf': etf,
                        'primary_weight': weight,
                        'correlated_etfs': correlated_etfs
                    })

        return {
            'top_weighted_etfs': top_weighted_etfs,
            'high_weight_high_correlation': high_weight_high_correlation,
            'concentration_risk': len(high_weight_high_correlation) > 0
        }

    def _generate_optimization_suggestions(self, risk_analysis: Dict[str, Any],
                                         weight_analysis: Dict[str, Any]) -> List[str]:
        """
        ç”Ÿæˆä¼˜åŒ–å»ºè®®

        Args:
            risk_analysis: é£é™©åˆ†æç»“æœ
            weight_analysis: æƒé‡åˆ†æç»“æœ

        Returns:
            ä¼˜åŒ–å»ºè®®åˆ—è¡¨
        """
        suggestions = []

        high_corr_count = len(risk_analysis['high_correlation_pairs'])
        moderate_corr_count = len(risk_analysis['moderate_correlation_pairs'])
        diversification_score = risk_analysis['diversification_score']

        # åŸºäºé£é™©ç­‰çº§çš„å»ºè®®
        if risk_analysis['risk_assessment']['risk_level'] == "é«˜é£é™©":
            suggestions.append("âš ï¸ æŠ•èµ„ç»„åˆç›¸å…³æ€§è¿‡é«˜ï¼Œå¼ºçƒˆå»ºè®®é‡æ–°é…ç½®ä»¥é™ä½é›†ä¸­é£é™©")

            if high_corr_count > 0:
                suggestions.append(f"ğŸ”„ å‘ç°{high_corr_count}å¯¹é«˜ç›¸å…³æ€§ETFï¼Œå»ºè®®è€ƒè™‘æ›¿æ¢å…¶ä¸­éƒ¨åˆ†æ ‡çš„")

            if diversification_score < 30:
                suggestions.append("ğŸ“Š åˆ†æ•£åŒ–è¯„åˆ†è¿‡ä½ï¼Œå»ºè®®å¢åŠ ä¸åŒè¡Œä¸šæˆ–é£æ ¼çš„ETF")

        elif risk_analysis['risk_assessment']['risk_level'] == "ä¸­ç­‰é£é™©":
            suggestions.append("âš–ï¸ æŠ•èµ„ç»„åˆå­˜åœ¨ä¸€å®šç›¸å…³æ€§é£é™©ï¼Œå¯è€ƒè™‘é€‚åº¦åˆ†æ•£")

            if moderate_corr_count > 2:
                suggestions.append("ğŸ“ˆ å»ºè®®å…³æ³¨ä¸­ç­‰ç›¸å…³æ€§ETFçš„é…ç½®æ¯”ä¾‹")

        # åŸºäºæƒé‡çš„å»ºè®®
        if weight_analysis['concentration_risk']:
            suggestions.append("ğŸ’° é«˜æƒé‡ETFä¸å…¶ä»–æŒä»“å­˜åœ¨è¾ƒé«˜ç›¸å…³æ€§ï¼Œå»ºè®®åˆ†æ•£æƒé‡")

        # é€šç”¨å»ºè®®
        if diversification_score < 50:
            suggestions.append("ğŸ¯ å»ºè®®åŠ å…¥ä¸åŒæ¿å—æˆ–èµ„äº§ç±»åˆ«çš„ETFä»¥æé«˜åˆ†æ•£åŒ–ç¨‹åº¦")

        suggestions.append("ğŸ“Š å®šæœŸç›‘æ§ETFç›¸å…³æ€§å˜åŒ–ï¼ŒåŠæ—¶è°ƒæ•´æŠ•èµ„ç»„åˆ")
        suggestions.append("ğŸ” åœ¨å¸‚åœºæç«¯è¡Œæƒ…ä¸‹ï¼Œç›¸å…³æ€§å¯èƒ½ä¸Šå‡ï¼Œéœ€åŠ å¼ºé£é™©ç®¡ç†")

        return suggestions

    def _generate_analysis_summary(self, risk_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆåˆ†ææ‘˜è¦

        Args:
            risk_analysis: é£é™©åˆ†æç»“æœ

        Returns:
            åˆ†ææ‘˜è¦
        """
        return {
            'total_etf_pairs': risk_analysis['correlation_distribution']['total_pairs'],
            'high_correlation_pairs': risk_analysis['correlation_distribution']['high_correlation_count'],
            'moderate_correlation_pairs': risk_analysis['correlation_distribution']['moderate_correlation_count'],
            'average_correlation': risk_analysis['average_correlation'],
            'maximum_correlation': risk_analysis['max_correlation'],
            'diversification_score': risk_analysis['diversification_score'],
            'risk_level': risk_analysis['risk_assessment']['risk_level'],
            'risk_score': risk_analysis['risk_assessment']['risk_score']
        }


def get_correlation_analyzer(high_correlation_threshold: float = 0.7,
                           moderate_correlation_threshold: float = 0.5) -> CorrelationAnalyzer:
    """è·å–ç›¸å…³æ€§åˆ†æå™¨å®ä¾‹"""
    return CorrelationAnalyzer(high_correlation_threshold, moderate_correlation_threshold)