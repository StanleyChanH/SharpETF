"""
æ•°æ®å¤„ç†æ¨¡å—
è®¡ç®—æ”¶ç›Šç‡ã€å¹´åŒ–ç»Ÿè®¡é‡å’Œæ•°æ®å¯¹é½
"""

import pandas as pd
import numpy as np
from typing import Tuple, Dict, Any
import logging

logger = logging.getLogger(__name__)


class DataProcessor:
    """æ•°æ®å¤„ç†ç±»"""
    
    def __init__(self, trading_days: int = 252):
        """
        åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        
        Args:
            trading_days: å¹´äº¤æ˜“å¤©æ•°ï¼Œé»˜è®¤252
        """
        self.trading_days = trading_days
    
    def process_data(self, data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame]:
        """
        å¤„ç†åŸå§‹æ•°æ®ï¼Œè®¡ç®—æ”¶ç›Šç‡å’Œç»Ÿè®¡é‡
        
        Args:
            data: åŸå§‹æ•°æ®DataFrameï¼ŒåŒ…å«trade_dateå’Œå„ETFä»·æ ¼åˆ—
            
        Returns:
            returns: æ—¥æ”¶ç›Šç‡DataFrame
            annual_mean: å¹´åŒ–æ”¶ç›Šç‡å‘é‡
            cov_matrix: å¹´åŒ–åæ–¹å·®çŸ©é˜µ
        """
        logger.info("ğŸ”„ å¼€å§‹å¤„ç†æ•°æ®...")
        
        # éªŒè¯è¾“å…¥æ•°æ®
        self._validate_input_data(data)
        
        # æå–ä»·æ ¼æ•°æ®ï¼ˆæ’é™¤trade_dateåˆ—ï¼‰
        price_data = data.iloc[:, 1:]
        
        # è®¡ç®—æ—¥æ”¶ç›Šç‡
        returns = self.calculate_returns(price_data)
        
        # è®¡ç®—å¹´åŒ–ç»Ÿè®¡é‡
        annual_mean, cov_matrix = self.calculate_annual_stats(returns)
        
        logger.info("âœ… æ•°æ®å¤„ç†å®Œæˆ")
        return returns, annual_mean, cov_matrix
    
    def _validate_input_data(self, data: pd.DataFrame) -> None:
        """
        éªŒè¯è¾“å…¥æ•°æ®
        
        Args:
            data: è¾“å…¥æ•°æ®DataFrame
        """
        if data.empty:
            raise ValueError("è¾“å…¥æ•°æ®ä¸ºç©º")
        
        if len(data.columns) < 2:
            raise ValueError("æ•°æ®åˆ—æ•°ä¸è¶³ï¼Œè‡³å°‘éœ€è¦trade_dateå’Œä¸€åˆ—ä»·æ ¼æ•°æ®")
        
        # æ£€æŸ¥trade_dateåˆ—æ˜¯å¦å­˜åœ¨
        if 'trade_date' not in data.columns:
            raise ValueError("æ•°æ®ä¸­ç¼ºå°‘trade_dateåˆ—")
        
        # æ£€æŸ¥ä»·æ ¼æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        price_columns = [col for col in data.columns if col != 'trade_date']
        for col in price_columns:
            if data[col].isnull().all():
                raise ValueError(f"ä»·æ ¼åˆ— {col} å…¨ä¸ºç¼ºå¤±å€¼")
            
            if (data[col] <= 0).any():
                logger.warning(f"âš ï¸ ä»·æ ¼åˆ— {col} åŒ…å«éæ­£å€¼")
    
    def calculate_returns(self, price_data: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æ—¥æ”¶ç›Šç‡
        
        Args:
            price_data: ä»·æ ¼æ•°æ®DataFrame
            
        Returns:
            æ—¥æ”¶ç›Šç‡DataFrame
        """
        try:
            # ä½¿ç”¨pct_changeè®¡ç®—ç™¾åˆ†æ¯”å˜åŒ–
            returns = price_data.pct_change()
            
            # åˆ é™¤ç¬¬ä¸€è¡Œï¼ˆNaNï¼‰
            returns = returns.dropna()
            
            # æ£€æŸ¥æ”¶ç›Šç‡æ•°æ®
            self._validate_returns(returns)
            
            logger.info(f"ğŸ“ˆ æ”¶ç›Šç‡è®¡ç®—å®Œæˆï¼Œå…± {len(returns)} ä¸ªäº¤æ˜“æ—¥")
            return returns
            
        except Exception as e:
            logger.error(f"âŒ æ”¶ç›Šç‡è®¡ç®—å¤±è´¥: {e}")
            raise
    
    def _validate_returns(self, returns: pd.DataFrame) -> None:
        """
        éªŒè¯æ”¶ç›Šç‡æ•°æ®
        
        Args:
            returns: æ”¶ç›Šç‡DataFrame
        """
        if returns.empty:
            raise ValueError("æ”¶ç›Šç‡æ•°æ®ä¸ºç©º")
        
        # æ£€æŸ¥å¼‚å¸¸å€¼
        for col in returns.columns:
            col_returns = returns[col]
            
            # æ£€æŸ¥æ ‡å‡†å·®
            std_dev = col_returns.std()
            if std_dev == 0:
                logger.warning(f"âš ï¸ {col} æ”¶ç›Šç‡æ ‡å‡†å·®ä¸º0")
            
            # æ£€æŸ¥æç«¯å€¼
            extreme_threshold = 0.5  # 50%çš„å•æ—¥æ¶¨è·Œå¹…
            extreme_count = (abs(col_returns) > extreme_threshold).sum()
            if extreme_count > 0:
                logger.warning(f"âš ï¸ {col} æœ‰ {extreme_count} ä¸ªæç«¯æ”¶ç›Šç‡ï¼ˆ>50%ï¼‰")
    
    def calculate_annual_stats(self, returns: pd.DataFrame) -> Tuple[pd.Series, pd.DataFrame]:
        """
        è®¡ç®—å¹´åŒ–ç»Ÿè®¡é‡
        
        Args:
            returns: æ—¥æ”¶ç›Šç‡DataFrame
            
        Returns:
            annual_mean: å¹´åŒ–æ”¶ç›Šç‡å‘é‡
            cov_matrix: å¹´åŒ–åæ–¹å·®çŸ©é˜µ
        """
        try:
            # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡
            annual_mean = returns.mean() * self.trading_days
            
            # è®¡ç®—å¹´åŒ–åæ–¹å·®çŸ©é˜µ
            cov_matrix = returns.cov() * self.trading_days
            
            # éªŒè¯åæ–¹å·®çŸ©é˜µ
            self._validate_cov_matrix(cov_matrix)
            
            logger.info("ğŸ“Š å¹´åŒ–ç»Ÿè®¡é‡è®¡ç®—å®Œæˆ")
            return annual_mean, cov_matrix
            
        except Exception as e:
            logger.error(f"âŒ å¹´åŒ–ç»Ÿè®¡é‡è®¡ç®—å¤±è´¥: {e}")
            raise
    
    def _validate_cov_matrix(self, cov_matrix: pd.DataFrame) -> None:
        """
        éªŒè¯åæ–¹å·®çŸ©é˜µ
        
        Args:
            cov_matrix: åæ–¹å·®çŸ©é˜µ
        """
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¯¹ç§°çŸ©é˜µ
        if not cov_matrix.equals(cov_matrix.T):
            logger.warning("âš ï¸ åæ–¹å·®çŸ©é˜µä¸å¯¹ç§°")
        
        # æ£€æŸ¥å¯¹è§’çº¿å…ƒç´ ï¼ˆæ–¹å·®ï¼‰æ˜¯å¦ä¸ºæ­£
        variances = np.diag(cov_matrix)
        if (variances <= 0).any():
            logger.warning("âš ï¸ åæ–¹å·®çŸ©é˜µåŒ…å«éæ­£æ–¹å·®")
        
        # æ£€æŸ¥çŸ©é˜µæ˜¯å¦æ­£å®š
        try:
            np.linalg.cholesky(cov_matrix)
        except np.linalg.LinAlgError:
            logger.warning("âš ï¸ åæ–¹å·®çŸ©é˜µä¸æ˜¯æ­£å®šçŸ©é˜µï¼Œå¯èƒ½å½±å“ä¼˜åŒ–ç»“æœ")
    
    def align_data(self, data_frames: list) -> pd.DataFrame:
        """
        å¯¹é½å¤šETFæ•°æ®ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰
        
        Args:
            data_frames: ETFæ•°æ®åˆ—è¡¨
            
        Returns:
            å¯¹é½åçš„DataFrame
        """
        if not data_frames:
            raise ValueError("æ²¡æœ‰æ•°æ®å¯å¯¹é½")
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªDataFrameä½œä¸ºåŸºç¡€
        aligned_data = data_frames[0]
        
        for df in data_frames[1:]:
            aligned_data = pd.merge(
                aligned_data, 
                df, 
                on='trade_date', 
                how='inner'
            )
        
        return aligned_data
    
    def get_data_summary(self, returns: pd.DataFrame, annual_mean: pd.Series, 
                        cov_matrix: pd.DataFrame) -> Dict[str, Any]:
        """
        è·å–æ•°æ®æ‘˜è¦ä¿¡æ¯
        
        Args:
            returns: æ—¥æ”¶ç›Šç‡DataFrame
            annual_mean: å¹´åŒ–æ”¶ç›Šç‡å‘é‡
            cov_matrix: å¹´åŒ–åæ–¹å·®çŸ©é˜µ
            
        Returns:
            æ•°æ®æ‘˜è¦å­—å…¸
        """
        summary = {
            "period": f"{len(returns)} ä¸ªäº¤æ˜“æ—¥",
            "start_date": returns.index.min().strftime('%Y-%m-%d') if hasattr(returns.index, 'strftime') else "N/A",
            "end_date": returns.index.max().strftime('%Y-%m-%d') if hasattr(returns.index, 'strftime') else "N/A",
            "etf_count": len(annual_mean),
            "annual_returns": {etf: f"{ret:.2%}" for etf, ret in annual_mean.items()},
            "volatilities": {etf: f"{np.sqrt(cov_matrix.loc[etf, etf]):.2%}" 
                           for etf in annual_mean.index}
        }
        
        return summary


def get_data_processor(trading_days: int = 252) -> DataProcessor:
    """è·å–æ•°æ®å¤„ç†å™¨å®ä¾‹"""
    return DataProcessor(trading_days)