"""
å¢å¼ºæŠ•èµ„ç»„åˆä¼˜åŒ–å™¨
é›†æˆé«˜çº§é‡åŒ–æŒ‡æ ‡æ¥æœ€å¤§åŒ–å¤æ™®æ¯”ç‡
"""

import pandas as pd
import numpy as np
from scipy.optimize import minimize
from typing import Dict, List, Tuple, Optional, Any
import logging
from .quant_signals import QuantSignals
from .evaluator import PortfolioEvaluator

logger = logging.getLogger(__name__)


class EnhancedPortfolioOptimizer:
    """å¢å¼ºæŠ•èµ„ç»„åˆä¼˜åŒ–å™¨"""

    def __init__(self, risk_free_rate: float = 0.02, trading_days: int = 252):
        """
        åˆå§‹åŒ–å¢å¼ºä¼˜åŒ–å™¨

        Args:
            risk_free_rate: æ— é£é™©åˆ©ç‡
            trading_days: å¹´äº¤æ˜“å¤©æ•°
        """
        self.risk_free_rate = risk_free_rate
        self.trading_days = trading_days
        self.quant_indicators = QuantSignals(trading_days, mode='advanced')
        self.evaluator = PortfolioEvaluator(trading_days, risk_free_rate)

    def optimize_with_enhanced_signals(self, returns: pd.DataFrame,
                                     prices: pd.DataFrame,
                                     signals: Dict[str, pd.Series],
                                     signal_weights: Optional[Dict[str, float]] = None) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        ä½¿ç”¨å¢å¼ºä¿¡å·è¿›è¡ŒæŠ•èµ„ç»„åˆä¼˜åŒ–

        Args:
            returns: å†å²æ”¶ç›Šç‡æ•°æ®
            prices: ä»·æ ¼æ•°æ®
            signals: é‡åŒ–ä¿¡å·å­—å…¸
            signal_weights: ä¿¡å·æƒé‡å­—å…¸

        Returns:
            (æœ€ä¼˜æƒé‡, ä¼˜åŒ–ç»“æœæŒ‡æ ‡)
        """
        logger.info("å¼€å§‹å¢å¼ºä¿¡å·æŠ•èµ„ç»„åˆä¼˜åŒ–...")

        # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡å’Œåæ–¹å·®çŸ©é˜µ
        annual_mean = returns.mean() * self.trading_days
        annual_cov = returns.cov() * self.trading_days

        # å¤„ç†ä¿¡å·æƒé‡
        if signal_weights is None:
            signal_weights = {
                'momentum_signal': 0.2,
                'quality_signal': 0.25,
                'technical_signal': 0.15,
                'risk_adjusted_signal': 0.2,
                'alpha_signal': 0.2
            }

        # è®¡ç®—ä¿¡å·è°ƒæ•´åçš„é¢„æœŸæ”¶ç›Š
        enhanced_expected_returns = self._calculate_enhanced_expected_returns(
            annual_mean, signals, signal_weights, returns
        )

        # è®¡ç®—ä¿¡å·è°ƒæ•´åçš„é£é™©æ¨¡å‹
        enhanced_cov_matrix = self._calculate_enhanced_cov_matrix(
            annual_cov, signals, signal_weights
        )

        # æ‰§è¡Œä¼˜åŒ–
        optimal_weights, metrics = self._optimize_with_enhanced_inputs(
            enhanced_expected_returns, enhanced_cov_matrix
        )

        # æ·»åŠ ä¿¡å·åˆ†æåˆ°ç»“æœä¸­
        metrics['signal_analysis'] = self._analyze_signal_contributions(
            signals, signal_weights, optimal_weights
        )

        logger.info("å¢å¼ºä¿¡å·æŠ•èµ„ç»„åˆä¼˜åŒ–å®Œæˆ")
        return optimal_weights, metrics

    def _calculate_enhanced_expected_returns(self, annual_mean: pd.Series,
                                           signals: Dict[str, pd.Series],
                                           signal_weights: Dict[str, float],
                                           returns: pd.DataFrame) -> pd.Series:
        """
        è®¡ç®—ä¿¡å·å¢å¼ºçš„é¢„æœŸæ”¶ç›Š

        Args:
            annual_mean: åŸå§‹å¹´åŒ–æ”¶ç›Šç‡
            signals: é‡åŒ–ä¿¡å·
            signal_weights: ä¿¡å·æƒé‡
            returns: å†å²æ”¶ç›Šç‡

        Returns:
            å¢å¼ºåçš„é¢„æœŸæ”¶ç›Šç‡
        """
        enhanced_returns = annual_mean.copy()

        for signal_name, signal_values in signals.items():
            if signal_name in signal_weights and isinstance(signal_values, pd.Series):
                weight = signal_weights[signal_name]

                # æ ‡å‡†åŒ–ä¿¡å·
                signal_normalized = (signal_values - signal_values.mean()) / signal_values.std()

                # è®¡ç®—ä¿¡å·çš„æ”¶ç›Šè´¡çŒ®
                signal_return_impact = signal_normalized * annual_mean.std() * weight * 0.1  # è°ƒæ•´ä¿¡å·å½±å“å¼ºåº¦

                # ç´¯ç§¯ä¿¡å·å½±å“
                enhanced_returns += signal_return_impact

        return enhanced_returns

    def _calculate_enhanced_cov_matrix(self, annual_cov: pd.DataFrame,
                                     signals: Dict[str, pd.Series],
                                     signal_weights: Dict[str, float]) -> pd.DataFrame:
        """
        è®¡ç®—ä¿¡å·å¢å¼ºçš„åæ–¹å·®çŸ©é˜µ

        Args:
            annual_cov: åŸå§‹å¹´åŒ–åæ–¹å·®çŸ©é˜µ
            signals: é‡åŒ–ä¿¡å·
            signal_weights: ä¿¡å·æƒé‡

        Returns:
            å¢å¼ºåçš„åæ–¹å·®çŸ©é˜µ
        """
        enhanced_cov = annual_cov.copy()

        # åŸºäºä¿¡å·ç›¸å…³æ€§è°ƒæ•´åæ–¹å·®
        signal_correlations = {}
        for signal_name, signal_values in signals.items():
            if signal_name in signal_weights and isinstance(signal_values, pd.Series):
                weight = signal_weights[signal_name]

                # è®¡ç®—ä¿¡å·ä¸æ”¶ç›Šçš„ç›¸å…³æ€§
                signal_corr = {}
                for etf in annual_cov.index:
                    if etf in signal_values.index:
                        correlation = signal_values[etf]
                        signal_corr[etf] = correlation * weight * 0.05  # è°ƒæ•´åæ–¹å·®è°ƒæ•´å¼ºåº¦

                signal_correlations[signal_name] = signal_corr

        # åº”ç”¨ä¿¡å·åæ–¹å·®è°ƒæ•´
        for i, etf1 in enumerate(annual_cov.index):
            for j, etf2 in enumerate(annual_cov.columns):
                if i != j:
                    # åŸºäºä¿¡å·ç›¸å…³æ€§è°ƒæ•´åæ–¹å·®
                    correlation_adjustment = 0
                    for signal_corr in signal_correlations.values():
                        if etf1 in signal_corr and etf2 in signal_corr:
                            correlation_adjustment += signal_corr[etf1] * signal_corr[etf2]

                    enhanced_cov.iloc[i, j] *= (1 + correlation_adjustment)

        # ç¡®ä¿åæ–¹å·®çŸ©é˜µæ­£å®š
        eigenvalues = np.linalg.eigvals(enhanced_cov)
        min_eigenvalue = np.min(eigenvalues)
        if min_eigenvalue <= 0:
            enhanced_cov += np.eye(len(enhanced_cov)) * abs(min_eigenvalue) * 1.1

        return enhanced_cov

    def _optimize_with_enhanced_inputs(self, enhanced_returns: pd.Series,
                                     enhanced_cov: pd.DataFrame) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        ä½¿ç”¨å¢å¼ºè¾“å…¥è¿›è¡Œä¼˜åŒ–

        Args:
            enhanced_returns: å¢å¼ºé¢„æœŸæ”¶ç›Š
            enhanced_cov: å¢å¼ºåæ–¹å·®çŸ©é˜µ

        Returns:
            (æœ€ä¼˜æƒé‡, ä¼˜åŒ–æŒ‡æ ‡)
        """
        n = len(enhanced_returns)

        # å®šä¹‰ç›®æ ‡å‡½æ•°ï¼šæœ€å¤§åŒ–å¤æ™®æ¯”ç‡
        def negative_sharpe_ratio(weights):
            portfolio_return = np.dot(weights, enhanced_returns.values)
            portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(enhanced.values, weights)))
            sharpe_ratio = (portfolio_return - self.risk_free_rate) / portfolio_vol
            return -sharpe_ratio

        # çº¦æŸæ¡ä»¶
        constraints = [
            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},  # æƒé‡å’Œä¸º1
        ]

        # é£é™©æ§åˆ¶çº¦æŸ
        def risk_constraint(weights):
            portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(enhanced_cov.values, weights)))
            return 0.20 - portfolio_vol  # æœ€å¤§æ³¢åŠ¨ç‡çº¦æŸ

        constraints.append({'type': 'ineq', 'fun': risk_constraint})

        # é›†ä¸­åº¦çº¦æŸ
        def concentration_constraint(weights):
            max_weight = np.max(weights)
            return 0.40 - max_weight  # æœ€å¤§å•ETFæƒé‡é™åˆ¶

        constraints.append({'type': 'ineq', 'fun': concentration_constraint})

        # è¾¹ç•Œæ¡ä»¶
        bounds = tuple((0, 1) for _ in range(n))

        # åˆå§‹çŒœæµ‹
        initial_weights = np.ones(n) / n

        try:
            result = minimize(
                negative_sharpe_ratio,
                initial_weights,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints,
                options={'ftol': 1e-9, 'disp': False}
            )

            if result.success:
                optimal_weights = result.x
                metrics = self._calculate_enhanced_portfolio_metrics(
                    optimal_weights, enhanced_returns, enhanced_cov
                )
                return optimal_weights, metrics
            else:
                logger.warning(f"å¢å¼ºä¼˜åŒ–å¤±è´¥: {result.message}")
                return self._fallback_enhanced_optimization(enhanced_returns, enhanced_cov)

        except Exception as e:
            logger.error(f"å¢å¼ºä¼˜åŒ–å¼‚å¸¸: {e}")
            return self._fallback_enhanced_optimization(enhanced_returns, enhanced_cov)

    def _calculate_enhanced_portfolio_metrics(self, weights: np.ndarray,
                                            enhanced_returns: pd.Series,
                                            enhanced_cov: pd.DataFrame) -> Dict[str, float]:
        """
        è®¡ç®—å¢å¼ºæŠ•èµ„ç»„åˆæŒ‡æ ‡

        Args:
            weights: æŠ•èµ„ç»„åˆæƒé‡
            enhanced_returns: å¢å¼ºé¢„æœŸæ”¶ç›Š
            enhanced_cov: å¢å¼ºåæ–¹å·®çŸ©é˜µ

        Returns:
            æŠ•èµ„ç»„åˆæŒ‡æ ‡
        """
        # åŸºç¡€æŒ‡æ ‡
        portfolio_return = np.dot(weights, enhanced_returns.values)
        portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(enhanced_cov.values, weights)))
        sharpe_ratio = (portfolio_return - self.risk_free_rate) / portfolio_vol

        metrics = {
            'portfolio_return': portfolio_return,
            'portfolio_volatility': portfolio_vol,
            'sharpe_ratio': sharpe_ratio,
            'enhanced_optimization': True
        }

        # é£é™©æŒ‡æ ‡
        weights_array = np.array(weights)

        # é›†ä¸­åº¦æŒ‡æ ‡
        hhi = np.sum(weights_array ** 2) * 10000  # èµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°
        metrics['concentration_hhi'] = hhi

        # æœ‰æ•ˆèµ„äº§æ•°é‡
        effective_assets = 1 / np.sum(weights_array ** 2)
        metrics['effective_assets'] = effective_assets

        # åˆ†æ•£åŒ–æ¯”ç‡
        weighted_vol = np.sum(weights_array * np.sqrt(np.diag(enhanced_cov)))
        diversification_ratio = weighted_vol / portfolio_vol
        metrics['diversification_ratio'] = diversification_ratio

        return metrics

    def _analyze_signal_contributions(self, signals: Dict[str, pd.Series],
                                    signal_weights: Dict[str, float],
                                    optimal_weights: np.ndarray) -> Dict[str, Any]:
        """
        åˆ†æä¿¡å·å¯¹ä¼˜åŒ–ç»“æœçš„è´¡çŒ®

        Args:
            signals: é‡åŒ–ä¿¡å·
            signal_weights: ä¿¡å·æƒé‡
            optimal_weights: æœ€ä¼˜æƒé‡

        Returns:
            ä¿¡å·è´¡çŒ®åˆ†æ
        """
        analysis = {}

        # è®¡ç®—å„ä¿¡å·çš„åŠ æƒè¡¨ç°
        signal_performance = {}
        for signal_name, signal_values in signals.items():
            if signal_name in signal_weights and isinstance(signal_values, pd.Series):
                weight = signal_weights[signal_name]
                # è®¡ç®—ä¿¡å·ä¸æƒé‡çš„ç›¸å…³æ€§
                signal_weight_corr = signal_values.corr(pd.Series(optimal_weights, index=signal_values.index))
                signal_performance[signal_name] = {
                    'weight': weight,
                    'correlation_with_weights': signal_weight_corr if not np.isnan(signal_weight_corr) else 0,
                    'signal_strength': signal_values.std()
                }

        analysis['signal_performance'] = signal_performance

        # è®¡ç®—ä¿¡å·ç»¼åˆè¯„åˆ†
        composite_score = sum(
            perf['weight'] * abs(perf['correlation_with_weights']) * perf['signal_strength']
            for perf in signal_performance.values()
        )
        analysis['composite_signal_score'] = composite_score

        # è¯†åˆ«ä¸»å¯¼ä¿¡å·
        dominant_signal = max(signal_performance.items(),
                            key=lambda x: abs(x[1]['correlation_with_weights']) * x[1]['signal_strength'])
        analysis['dominant_signal'] = dominant_signal[0]

        return analysis

    def _fallback_enhanced_optimization(self, enhanced_returns: pd.Series,
                                      enhanced_cov: pd.DataFrame) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        å¤‡ç”¨å¢å¼ºä¼˜åŒ–æ–¹æ³•

        Args:
            enhanced_returns: å¢å¼ºé¢„æœŸæ”¶ç›Š
            enhanced_cov: å¢å¼ºåæ–¹å·®çŸ©é˜µ

        Returns:
            (å¤‡ç”¨æƒé‡, å¤‡ç”¨æŒ‡æ ‡)
        """
        logger.info("ä½¿ç”¨å¤‡ç”¨å¢å¼ºä¼˜åŒ–æ–¹æ³•...")

        n = len(enhanced_returns)

        # æ–¹æ³•1: ç­‰é£é™©è´¡çŒ®ç»„åˆ
        try:
            risk_parity_weights = self._calculate_risk_parity_weights(enhanced_cov)
            metrics = self._calculate_enhanced_portfolio_metrics(
                risk_parity_weights, enhanced_returns, enhanced_cov
            )
            return risk_parity_weights, metrics
        except Exception as e:
            logger.warning(f"é£é™©å¹³ä»·å¤‡ç”¨æ–¹æ³•å¤±è´¥: {e}")

        # æ–¹æ³•2: ç­‰æƒé‡ç»„åˆ
        equal_weights = np.ones(n) / n
        metrics = self._calculate_enhanced_portfolio_metrics(
            equal_weights, enhanced_returns, enhanced_cov
        )

        return equal_weights, metrics

    def _calculate_risk_parity_weights(self, cov_matrix: pd.DataFrame) -> np.ndarray:
        """
        è®¡ç®—é£é™©å¹³ä»·æƒé‡

        Args:
            cov_matrix: åæ–¹å·®çŸ©é˜µ

        Returns:
            é£é™©å¹³ä»·æƒé‡
        """
        n = cov_matrix.shape[0]

        def risk_budget_objective(weights):
            portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix.values, weights)))
            marginal_contrib = np.dot(cov_matrix.values, weights) / portfolio_vol
            contrib = weights * marginal_contrib
            target_contrib = 1 / n
            return np.sum((contrib - target_contrib) ** 2)

        constraints = [{'type': 'eq', 'fun': lambda x: np.sum(x) - 1}]
        bounds = tuple((0, 1) for _ in range(n))
        initial_weights = np.ones(n) / n

        result = minimize(
            risk_budget_objective,
            initial_weights,
            method='SLSQP',
            bounds=bounds,
            constraints=constraints
        )

        return result.x if result.success else initial_weights

    def compare_enhanced_vs_traditional(self, returns: pd.DataFrame,
                                      prices: pd.DataFrame) -> Dict[str, Any]:
        """
        æ¯”è¾ƒå¢å¼ºä¼˜åŒ–ä¸ä¼ ç»Ÿä¼˜åŒ–çš„ç»“æœ

        Args:
            returns: å†å²æ”¶ç›Šç‡
            prices: ä»·æ ¼æ•°æ®

        Returns:
            æ¯”è¾ƒç»“æœ
        """
        logger.info("å¼€å§‹æ¯”è¾ƒå¢å¼ºä¼˜åŒ–ä¸ä¼ ç»Ÿä¼˜åŒ–...")

        comparison = {}

        try:
            # ç”Ÿæˆå¢å¼ºä¿¡å·
            signals = self.quant_indicators.generate_signals(returns, prices)

            # ä¼ ç»Ÿä¼˜åŒ–
            annual_mean_traditional = returns.mean() * self.trading_days
            annual_cov_traditional = returns.cov() * self.trading_days

            traditional_weights, traditional_metrics = self._optimize_with_enhanced_inputs(
                annual_mean_traditional, annual_cov_traditional
            )

            # å¢å¼ºä¼˜åŒ–
            if signals:
                enhanced_weights, enhanced_metrics = self.optimize_with_enhanced_signals(
                    returns, prices, signals
                )

                comparison['traditional'] = {
                    'weights': traditional_weights,
                    'metrics': traditional_metrics,
                    'method': 'Traditional Optimization'
                }

                comparison['enhanced'] = {
                    'weights': enhanced_weights,
                    'metrics': enhanced_metrics,
                    'method': 'Enhanced Signal Optimization'
                }

                # è®¡ç®—æ”¹è¿›æŒ‡æ ‡
                sharpe_improvement = enhanced_metrics['sharpe_ratio'] - traditional_metrics['sharpe_ratio']
                comparison['improvement'] = {
                    'sharpe_ratio_improvement': sharpe_improvement,
                    'sharpe_improvement_pct': (sharpe_improvement / traditional_metrics['sharpe_ratio']) * 100 if traditional_metrics['sharpe_ratio'] != 0 else 0,
                    'volatility_change': enhanced_metrics['portfolio_volatility'] - traditional_metrics['portfolio_volatility'],
                    'return_change': enhanced_metrics['portfolio_return'] - traditional_metrics['portfolio_return']
                }

                # ä¿¡å·åˆ†æ
                comparison['signal_analysis'] = enhanced_metrics.get('signal_analysis', {})

            logger.info("ä¼˜åŒ–æ¯”è¾ƒå®Œæˆ")

        except Exception as e:
            logger.error(f"ä¼˜åŒ–æ¯”è¾ƒå¤±è´¥: {e}")
            comparison = {'error': str(e)}

        return comparison

    def get_optimization_recommendations(self, comparison: Dict[str, Any]) -> List[str]:
        """
        åŸºäºæ¯”è¾ƒç»“æœç”Ÿæˆä¼˜åŒ–å»ºè®®

        Args:
            comparison: æ¯”è¾ƒç»“æœ

        Returns:
            ä¼˜åŒ–å»ºè®®åˆ—è¡¨
        """
        recommendations = []

        if 'error' in comparison:
            recommendations.append("ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡")
            return recommendations

        if 'improvement' in comparison:
            improvement = comparison['improvement']

            # å¤æ™®æ¯”ç‡æ”¹è¿›å»ºè®®
            if improvement['sharpe_ratio_improvement'] > 0.1:
                recommendations.append("âœ… å¢å¼ºä¿¡å·ä¼˜åŒ–æ˜¾è‘—æå‡äº†å¤æ™®æ¯”ç‡ï¼Œå»ºè®®é‡‡ç”¨")
            elif improvement['sharpe_ratio_improvement'] > 0:
                recommendations.append("âœ… å¢å¼ºä¿¡å·ä¼˜åŒ–ç•¥å¾®æå‡äº†å¤æ™®æ¯”ç‡")
            else:
                recommendations.append("âš ï¸ å¢å¼ºä¿¡å·ä¼˜åŒ–æœªèƒ½æå‡å¤æ™®æ¯”ç‡ï¼Œå»ºè®®æ£€æŸ¥ä¿¡å·è´¨é‡")

            # é£é™©è°ƒæ•´å»ºè®®
            if improvement['volatility_change'] > 0.01:
                recommendations.append("âš ï¸ å¢å¼ºä¼˜åŒ–å¢åŠ äº†æŠ•èµ„ç»„åˆæ³¢åŠ¨ç‡ï¼Œå»ºè®®åŠ å¼ºé£é™©æ§åˆ¶")
            elif improvement['volatility_change'] < -0.01:
                recommendations.append("âœ… å¢å¼ºä¼˜åŒ–é™ä½äº†æŠ•èµ„ç»„åˆæ³¢åŠ¨ç‡")

            # æ”¶ç›Šæå‡å»ºè®®
            if improvement['return_change'] > 0.01:
                recommendations.append("âœ… å¢å¼ºä¼˜åŒ–æå‡äº†é¢„æœŸæ”¶ç›Š")
            elif improvement['return_change'] < -0.01:
                recommendations.append("âš ï¸ å¢å¼ºä¼˜åŒ–é™ä½äº†é¢„æœŸæ”¶ç›Š")

        # ä¿¡å·åˆ†æå»ºè®®
        if 'signal_analysis' in comparison and 'dominant_signal' in comparison['signal_analysis']:
            dominant = comparison['signal_analysis']['dominant_signal']
            recommendations.append(f"ğŸ’¡ {dominant} æ˜¯ä¸»å¯¼ä¿¡å·ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨æ­¤ç±»æŒ‡æ ‡")

        return recommendations


def get_enhanced_portfolio_optimizer(risk_free_rate: float = 0.02,
                                   trading_days: int = 252) -> EnhancedPortfolioOptimizer:
    """è·å–å¢å¼ºæŠ•èµ„ç»„åˆä¼˜åŒ–å™¨å®ä¾‹"""
    return EnhancedPortfolioOptimizer(risk_free_rate, trading_days)