"""
ç®€åŒ–å¢å¼ºæŠ•èµ„ç»„åˆä¼˜åŒ–å™¨
åŸºäºé‡åŒ–ä¿¡å·è¿›è¡Œç®€å•ä½†æœ‰æ•ˆçš„æŠ•èµ„ç»„åˆä¼˜åŒ–
"""

import pandas as pd
import numpy as np
from scipy.optimize import minimize
from typing import Dict, List, Tuple, Optional, Any
import logging

logger = logging.getLogger(__name__)


class SimpleEnhancedOptimizer:
    """ç®€åŒ–å¢å¼ºæŠ•èµ„ç»„åˆä¼˜åŒ–å™¨"""

    def __init__(self, risk_free_rate: float = 0.02, trading_days: int = 252):
        """
        åˆå§‹åŒ–ç®€åŒ–å¢å¼ºä¼˜åŒ–å™¨

        Args:
            risk_free_rate: æ— é£é™©åˆ©ç‡
            trading_days: å¹´äº¤æ˜“å¤©æ•°
        """
        self.risk_free_rate = risk_free_rate
        self.trading_days = trading_days

    def optimize_with_signals(self, returns: pd.DataFrame,
                            signals: Dict[str, Any]) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        åŸºäºä¿¡å·è¿›è¡ŒæŠ•èµ„ç»„åˆä¼˜åŒ–

        Args:
            returns: å†å²æ”¶ç›Šç‡æ•°æ®
            signals: é‡åŒ–ä¿¡å·æ•°æ®

        Returns:
            (æœ€ä¼˜æƒé‡, ä¼˜åŒ–ç»“æœæŒ‡æ ‡)
        """
        logger.info("ğŸš€ å¼€å§‹åŸºäºä¿¡å·çš„å¢å¼ºä¼˜åŒ–...")

        try:
            if not signals or 'composite_signal' not in signals:
                # å¦‚æœæ²¡æœ‰ä¿¡å·ï¼Œä½¿ç”¨ä¼ ç»Ÿä¼˜åŒ–
                return self._traditional_optimization(returns)

            # è·å–ä¿¡å·è°ƒæ•´åçš„é¢„æœŸæ”¶ç›Š
            composite_signal = signals['composite_signal']

            # åŸºç¡€é¢„æœŸæ”¶ç›Š
            base_expected_returns = returns.mean() * self.trading_days

            # ä¿¡å·è°ƒæ•´ï¼šç»™é«˜ä¿¡å·çš„ETFæ›´é«˜çš„é¢„æœŸæ”¶ç›Š
            signal_adjustment = composite_signal * base_expected_returns.std() * 0.3  # è°ƒæ•´å¼ºåº¦
            enhanced_expected_returns = base_expected_returns + signal_adjustment

            # ç¡®ä¿é¢„æœŸæ”¶ç›Šä¸ºæ­£
            enhanced_expected_returns = enhanced_expected_returns.clip(lower=0.01)

            # åæ–¹å·®çŸ©é˜µ
            cov_matrix = returns.cov() * self.trading_days

            # æ‰§è¡Œä¼˜åŒ–
            optimal_weights, metrics = self._optimize_portfolio(
                enhanced_expected_returns, cov_matrix
            )

            # æ·»åŠ ä¿¡å·åˆ†æ
            metrics['signal_analysis'] = self._analyze_signal_weights(
                composite_signal, optimal_weights, returns.columns
            )

            logger.info("âœ… åŸºäºä¿¡å·çš„å¢å¼ºä¼˜åŒ–å®Œæˆ")
            return optimal_weights, metrics

        except Exception as e:
            logger.error(f"âŒ å¢å¼ºä¼˜åŒ–å¤±è´¥: {e}")
            return self._traditional_optimization(returns)

    def _traditional_optimization(self, returns: pd.DataFrame) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        ä¼ ç»Ÿå¤æ™®æ¯”ç‡ä¼˜åŒ–

        Args:
            returns: å†å²æ”¶ç›Šç‡

        Returns:
            (æœ€ä¼˜æƒé‡, ä¼˜åŒ–æŒ‡æ ‡)
        """
        expected_returns = returns.mean() * self.trading_days
        cov_matrix = returns.cov() * self.trading_days

        return self._optimize_portfolio(expected_returns, cov_matrix)

    def _optimize_portfolio(self, expected_returns: pd.Series,
                          cov_matrix: pd.DataFrame) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        æ‰§è¡ŒæŠ•èµ„ç»„åˆä¼˜åŒ–

        Args:
            expected_returns: é¢„æœŸæ”¶ç›Šç‡
            cov_matrix: åæ–¹å·®çŸ©é˜µ

        Returns:
            (æœ€ä¼˜æƒé‡, ä¼˜åŒ–æŒ‡æ ‡)
        """
        n = len(expected_returns)

        def negative_sharpe_ratio(weights):
            portfolio_return = np.dot(weights, expected_returns.values)
            portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix.values, weights)))
            sharpe_ratio = (portfolio_return - self.risk_free_rate) / portfolio_vol
            return -sharpe_ratio

        # çº¦æŸæ¡ä»¶
        constraints = [
            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},  # æƒé‡å’Œä¸º1
        ]

        # é£é™©æ§åˆ¶
        def risk_constraint(weights):
            portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix.values, weights)))
            return 0.25 - portfolio_vol  # æœ€å¤§æ³¢åŠ¨ç‡25%

        constraints.append({'type': 'ineq', 'fun': risk_constraint})

        # é›†ä¸­åº¦çº¦æŸ
        def concentration_constraint(weights):
            return 0.5 - np.max(weights)  # æœ€å¤§å•ä¸ªæƒé‡50%

        constraints.append({'type': 'ineq', 'fun': concentration_constraint})

        # è¾¹ç•Œæ¡ä»¶
        bounds = tuple((0, 0.5) for _ in range(n))  # å•ä¸ªETFæœ€å¤§50%

        # åˆå§‹çŒœæµ‹ - ç­‰æƒé‡
        initial_weights = np.ones(n) / n

        try:
            result = minimize(
                negative_sharpe_ratio,
                initial_weights,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints,
                options={'ftol': 1e-9, 'disp': False}
            )

            if result.success:
                optimal_weights = result.x
                metrics = self._calculate_portfolio_metrics(
                    optimal_weights, expected_returns, cov_matrix
                )
                return optimal_weights, metrics
            else:
                # å¦‚æœä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç­‰æƒé‡
                equal_weights = np.ones(n) / n
                metrics = self._calculate_portfolio_metrics(
                    equal_weights, expected_returns, cov_matrix
                )
                return equal_weights, metrics

        except Exception as e:
            logger.error(f"ä¼˜åŒ–è¿‡ç¨‹å¼‚å¸¸: {e}")
            # è¿”å›ç­‰æƒé‡
            equal_weights = np.ones(n) / n
            metrics = self._calculate_portfolio_metrics(
                equal_weights, expected_returns, cov_matrix
            )
            return equal_weights, metrics

    def _calculate_portfolio_metrics(self, weights: np.ndarray,
                                   expected_returns: pd.Series,
                                   cov_matrix: pd.DataFrame) -> Dict[str, float]:
        """
        è®¡ç®—æŠ•èµ„ç»„åˆæŒ‡æ ‡

        Args:
            weights: æŠ•èµ„ç»„åˆæƒé‡
            expected_returns: é¢„æœŸæ”¶ç›Šç‡
            cov_matrix: åæ–¹å·®çŸ©é˜µ

        Returns:
            æŠ•èµ„ç»„åˆæŒ‡æ ‡
        """
        portfolio_return = np.dot(weights, expected_returns.values)
        portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix.values, weights)))
        sharpe_ratio = (portfolio_return - self.risk_free_rate) / portfolio_vol

        metrics = {
            'portfolio_return': portfolio_return,
            'portfolio_volatility': portfolio_vol,
            'sharpe_ratio': sharpe_ratio
        }

        # æ·»åŠ é¢å¤–æŒ‡æ ‡
        weights_array = np.array(weights)

        # é›†ä¸­åº¦æŒ‡æ ‡
        hhi = np.sum(weights_array ** 2) * 10000
        metrics['concentration_hhi'] = hhi

        # æœ‰æ•ˆèµ„äº§æ•°é‡
        effective_assets = 1 / np.sum(weights_array ** 2)
        metrics['effective_assets'] = effective_assets

        # åˆ†æ•£åŒ–æ¯”ç‡
        weighted_vol = np.sum(weights_array * np.sqrt(np.diag(cov_matrix)))
        diversification_ratio = weighted_vol / portfolio_vol
        metrics['diversification_ratio'] = diversification_ratio

        return metrics

    def _analyze_signal_weights(self, signals: pd.Series, weights: np.ndarray,
                              etf_codes: List[str]) -> Dict[str, Any]:
        """
        åˆ†æä¿¡å·ä¸æƒé‡çš„å…³ç³»

        Args:
            signals: ç»¼åˆä¿¡å·
            weights: æœ€ä¼˜æƒé‡
            etf_codes: ETFä»£ç åˆ—è¡¨

        Returns:
            ä¿¡å·æƒé‡åˆ†æ
        """
        try:
            # åˆ›å»ºDataFrameä¾¿äºåˆ†æ
            analysis_df = pd.DataFrame({
                'signal': signals,
                'weight': weights,
                'etf_code': etf_codes
            })

            # è®¡ç®—ä¿¡å·ä¸æƒé‡çš„ç›¸å…³æ€§
            correlation = analysis_df['signal'].corr(analysis_df['weight'])

            # æ‰¾å‡ºé«˜ä¿¡å·é«˜æƒé‡çš„ETF
            high_signal_threshold = signals.quantile(0.75)
            high_weight_threshold = np.percentile(weights, 75)

            top_signal_etfs = analysis_df[analysis_df['signal'] > high_signal_threshold]
            top_weight_etfs = analysis_df[analysis_df['weight'] > high_weight_threshold]

            # ä¿¡å·ä¸€è‡´æ€§åˆ†æ
            consistent_picks = set(top_signal_etfs['etf_code']) & set(top_weight_etfs['etf_code'])

            return {
                'signal_weight_correlation': correlation if not np.isnan(correlation) else 0,
                'top_signal_etfs': top_signal_etfs['etf_code'].tolist(),
                'top_weight_etfs': top_weight_etfs['etf_code'].tolist(),
                'consistent_picks': list(consistent_picks),
                'signal_effectiveness': 'high' if correlation > 0.3 else 'medium' if correlation > 0.1 else 'low'
            }

        except Exception as e:
            logger.error(f"åˆ†æä¿¡å·æƒé‡å…³ç³»å¤±è´¥: {e}")
            return {'signal_effectiveness': 'unknown'}

    def compare_with_traditional(self, returns: pd.DataFrame,
                              signals: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ¯”è¾ƒå¢å¼ºä¼˜åŒ–ä¸ä¼ ç»Ÿä¼˜åŒ–

        Args:
            returns: å†å²æ”¶ç›Šç‡
            signals: é‡åŒ–ä¿¡å·

        Returns:
            æ¯”è¾ƒç»“æœ
        """
        try:
            # ä¼ ç»Ÿä¼˜åŒ–
            traditional_weights, traditional_metrics = self._traditional_optimization(returns)

            # å¢å¼ºä¼˜åŒ–
            enhanced_weights, enhanced_metrics = self.optimize_with_signals(returns, signals)

            # è®¡ç®—æ”¹è¿›æŒ‡æ ‡
            sharpe_improvement = enhanced_metrics['sharpe_ratio'] - traditional_metrics['sharpe_ratio']
            return_improvement = enhanced_metrics['portfolio_return'] - traditional_metrics['portfolio_return']
            volatility_change = enhanced_metrics['portfolio_volatility'] - traditional_metrics['portfolio_volatility']

            comparison = {
                'traditional': {
                    'weights': traditional_weights,
                    'metrics': traditional_metrics
                },
                'enhanced': {
                    'weights': enhanced_weights,
                    'metrics': enhanced_metrics
                },
                'improvement': {
                    'sharpe_ratio_improvement': sharpe_improvement,
                    'sharpe_improvement_pct': (sharpe_improvement / traditional_metrics['sharpe_ratio']) * 100 if traditional_metrics['sharpe_ratio'] != 0 else 0,
                    'return_change': return_improvement,
                    'volatility_change': volatility_change
                }
            }

            return comparison

        except Exception as e:
            logger.error(f"æ¯”è¾ƒä¼˜åŒ–ç»“æœå¤±è´¥: {e}")
            return {}

    def get_optimization_recommendations(self, comparison: Dict[str, Any]) -> List[str]:
        """
        åŸºäºæ¯”è¾ƒç»“æœç”Ÿæˆä¼˜åŒ–å»ºè®®

        Args:
            comparison: æ¯”è¾ƒç»“æœ

        Returns:
            ä¼˜åŒ–å»ºè®®åˆ—è¡¨
        """
        recommendations = []

        try:
            if not comparison or 'improvement' not in comparison:
                return ["ä¼˜åŒ–ç»“æœæ¯”è¾ƒå¤±è´¥ï¼Œå»ºè®®åŸºäºåŸºç¡€åˆ†æè¿›è¡ŒæŠ•èµ„å†³ç­–"]

            improvement = comparison['improvement']

            # å¤æ™®æ¯”ç‡æ”¹è¿›å»ºè®®
            sharpe_imp = improvement.get('sharpe_ratio_improvement', 0)
            if sharpe_imp > 0.1:
                recommendations.append("âœ… å¢å¼ºä¼˜åŒ–æ˜¾è‘—æå‡äº†å¤æ™®æ¯”ç‡ï¼Œå»ºè®®é‡‡ç”¨ä¿¡å·é©±åŠ¨ç­–ç•¥")
            elif sharpe_imp > 0.01:
                recommendations.append("ğŸ“ˆ å¢å¼ºä¼˜åŒ–ç•¥å¾®æå‡äº†å¤æ™®æ¯”ç‡ï¼Œå¯è€ƒè™‘é‡‡ç”¨")
            elif sharpe_imp < -0.01:
                recommendations.append("âš ï¸ å¢å¼ºä¼˜åŒ–é™ä½äº†å¤æ™®æ¯”ç‡ï¼Œå»ºè®®ä½¿ç”¨ä¼ ç»Ÿä¼˜åŒ–")

            # æ”¶ç›Šæ”¹è¿›å»ºè®®
            return_imp = improvement.get('return_change', 0)
            if return_imp > 0.02:
                recommendations.append("ğŸ’° å¢å¼ºä¼˜åŒ–æå‡äº†é¢„æœŸæ”¶ç›Šï¼Œå»ºè®®é‡ç‚¹å…³æ³¨")
            elif return_imp < -0.02:
                recommendations.append("ğŸ“‰ å¢å¼ºä¼˜åŒ–é™ä½äº†é¢„æœŸæ”¶ç›Šï¼Œéœ€è¦æƒè¡¡é£é™©æ”¶ç›Š")

            # é£é™©å˜åŒ–å»ºè®®
            vol_change = improvement.get('volatility_change', 0)
            if vol_change > 0.02:
                recommendations.append("âš ï¸ å¢å¼ºä¼˜åŒ–å¢åŠ äº†æŠ•èµ„ç»„åˆé£é™©ï¼Œéœ€è¦åŠ å¼ºé£é™©æ§åˆ¶")
            elif vol_change < -0.02:
                recommendations.append("ğŸ›¡ï¸ å¢å¼ºä¼˜åŒ–é™ä½äº†æŠ•èµ„ç»„åˆé£é™©ï¼Œæœ‰åŠ©äºé£é™©æ§åˆ¶")

            # ç»¼åˆå»ºè®®
            if sharpe_imp > 0 and return_imp > 0:
                recommendations.append("ğŸ¯ å¢å¼ºä¼˜åŒ–åœ¨é£é™©è°ƒæ•´æ”¶ç›Šæ–¹é¢è¡¨ç°ä¼˜ç§€ï¼Œå»ºè®®ä¼˜å…ˆè€ƒè™‘")
            elif sharpe_imp > 0 and vol_change < 0:
                recommendations.append("ğŸ† å¢å¼ºä¼˜åŒ–å®ç°äº†æ›´å¥½çš„é£é™©è°ƒæ•´æ”¶ç›Šï¼Œæ˜¯ç†æƒ³çš„é€‰æ‹©")

        except Exception as e:
            logger.error(f"ç”Ÿæˆä¼˜åŒ–å»ºè®®å¤±è´¥: {e}")
            recommendations = ["å»ºè®®ç”Ÿæˆå¤±è´¥ï¼Œè¯·åŸºäºä¸“ä¸šåˆ¤æ–­è¿›è¡Œå†³ç­–"]

        return recommendations


def get_simple_enhanced_optimizer(risk_free_rate: float = 0.02,
                                 trading_days: int = 252) -> SimpleEnhancedOptimizer:
    """è·å–ç®€åŒ–å¢å¼ºä¼˜åŒ–å™¨å®ä¾‹"""
    return SimpleEnhancedOptimizer(risk_free_rate, trading_days)